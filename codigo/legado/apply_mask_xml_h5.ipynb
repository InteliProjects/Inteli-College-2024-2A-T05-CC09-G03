{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAh-H8wMm2vl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqSfRgkry1hb",
        "outputId": "f6e83747-0755-4d17-d6e4-88d34c2c0977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/sda3/home2/tony-sousa/cc09-cow-project\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Mostrar o diretório de trabalho atual\n",
        "print(os.getcwd())\n",
        "# print(os.listdir('./cc09-cow-project/'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgBZ3XfFMAp",
        "outputId": "c812458b-acfd-4a2d-a834-fa0ecb63ab01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.21.2 (from opencv-python)\n",
            "  Using cached numpy-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "Using cached numpy-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "Installing collected packages: numpy, opencv-python\n",
            "Successfully installed numpy-2.1.1 opencv-python-4.10.0.84\n",
            "Requirement already satisfied: numpy in ./.cc09-env/lib/python3.12/site-packages (2.1.1)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.54.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.cc09-env/lib/python3.12/site-packages (from matplotlib) (2.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.cc09-env/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.cc09-env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.cc09-env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Using cached matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "Using cached contourpy-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.54.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Using cached kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-10.4.0 pyparsing-3.1.4\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.66.5\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in ./.cc09-env/lib/python3.12/site-packages (from h5py) (2.1.1)\n",
            "Using cached h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "Installing collected packages: h5py\n",
            "Successfully installed h5py-3.12.1\n",
            "Collecting xmltodict\n",
            "  Using cached xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Using cached xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement xml.etree.ElementTree (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for xml.etree.ElementTree\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Instalação das bibliotecas necessárias\n",
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install tqdm\n",
        "!pip install h5py\n",
        "!pip install xmltodict\n",
        "!pip install xml.etree.ElementTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xHY-rr6w0JiX"
      },
      "outputs": [],
      "source": [
        "# Listar arquivos e diretórios\n",
        "\n",
        "# folder_path = './cc09-cow-project'\n",
        "folder_path = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processamento dos Frames Coloridos ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parseando anotações XML: 100%|██████████| 81992/81992 [00:00<00:00, 553647.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processando parte 1 de 5: frames 0 a 16398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extraindo frames de video_colorido_concatenado_10fps.mp4 - Parte 0 a 16398: 100%|██████████| 16398/16398 [00:25<00:00, 646.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atualizando o dataset existente: color_chunk_1\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "import xml.etree.ElementTree as ET  # Considere usar 'from lxml import etree as ET' para melhor desempenho\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ======= 1. Configurações Iniciais =======\n",
        "\n",
        "# Caminhos para os vídeos e o arquivo de anotações XML\n",
        "folder_path = '.' \n",
        "color_video_path = os.path.join(folder_path, 'videos', 'video_colorido_concatenado_10fps.mp4')\n",
        "thermal_video_path = os.path.join(folder_path, 'videos', 'video_preto_branco_10fps.mp4')\n",
        "annotations_path = os.path.join(folder_path, 'xml', 'annotations_colorido_correct.xml')\n",
        "\n",
        "# Diretório para salvar os arquivos .h5\n",
        "data_dir = os.path.join(folder_path, 'dados')\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "masked_color_frames_h5_path = os.path.join(data_dir, 'masked_color_frames.h5')\n",
        "color_frames_h5_path = os.path.join(data_dir, 'color_frames.h5')\n",
        "thermal_frames_h5_path = os.path.join(data_dir, 'thermal_frames.h5')\n",
        "\n",
        "# ======= 2. Funções Auxiliares =======\n",
        "\n",
        "def extract_frames(video_path, start_frame, end_frame):\n",
        "    \"\"\"\n",
        "    Extrai frames de um vídeo em um intervalo específico.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Caminho para o arquivo de vídeo.\n",
        "        start_frame (int): Frame inicial.\n",
        "        end_frame (int): Frame final.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (frames, frame_names)\n",
        "            - frames (list): Lista de frames extraídos.\n",
        "            - frame_names (list): Lista de nomes dos frames.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Erro: Não foi possível abrir o vídeo: {video_path}\")\n",
        "        return [], []\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "    frames = []\n",
        "    frame_names = []\n",
        "\n",
        "    for idx in tqdm(range(start_frame, end_frame), desc=f\"Extraindo frames de {os.path.basename(video_path)} - Parte {start_frame} a {end_frame}\"):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(f\"Warning: Frame {idx} não pôde ser lido. Parando a extração.\")\n",
        "            break\n",
        "        frames.append(frame)\n",
        "        # Extrair o nome do frame a partir do índice\n",
        "        frame_name = f\"frame_{idx:06d}\"\n",
        "        frame_names.append(frame_name)\n",
        "\n",
        "    cap.release()\n",
        "    return frames, frame_names\n",
        "\n",
        "def parse_annotations(annotations_path, relevant_frames, image_shape):\n",
        "    \"\"\"\n",
        "    Parseia o arquivo XML de anotações e cria máscaras para os frames relevantes.\n",
        "\n",
        "    Args:\n",
        "        annotations_path (str): Caminho para o arquivo XML de anotações.\n",
        "        relevant_frames (set): Conjunto de IDs de frames relevantes.\n",
        "        image_shape (tuple): Forma da imagem (altura, largura, canais).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dicionário mapeando números de frames para suas máscaras combinadas.\n",
        "    \"\"\"\n",
        "    tree = ET.parse(annotations_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    masks_per_frame = {}\n",
        "\n",
        "    for image in tqdm(root.findall('image'), desc=\"Parseando anotações XML\"):\n",
        "        frame_id = int(image.attrib['id'])\n",
        "        if frame_id not in relevant_frames:\n",
        "            continue  # Ignorar frames não relevantes\n",
        "        for polygon in image.findall('polygon'):\n",
        "            label = polygon.attrib.get('label', 'unknown')\n",
        "            points_str = polygon.attrib['points']\n",
        "            points = []\n",
        "            for point in points_str.split(';'):\n",
        "                x_str, y_str = point.strip().split(',')\n",
        "                x = float(x_str)\n",
        "                y = float(y_str)\n",
        "                points.append((x, y))\n",
        "            # Criar máscara para o polígono atual\n",
        "            single_mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
        "            cv2.fillPoly(single_mask, [np.array(points, dtype=np.int32)], color=255)\n",
        "\n",
        "            if frame_id in masks_per_frame:\n",
        "                # Combinar a nova máscara com a existente usando operação lógica OR\n",
        "                masks_per_frame[frame_id] = cv2.bitwise_or(masks_per_frame[frame_id], single_mask)\n",
        "            else:\n",
        "                masks_per_frame[frame_id] = single_mask\n",
        "\n",
        "    return masks_per_frame\n",
        "\n",
        "def apply_masks(color_frames, masks_per_frame, frame_ids):\n",
        "    \"\"\"\n",
        "    Aplica as máscaras aos frames coloridos.\n",
        "\n",
        "    Args:\n",
        "        color_frames (list): Lista de frames coloridos.\n",
        "        masks_per_frame (dict): Dicionário mapeando números de frames para suas máscaras.\n",
        "        frame_ids (list): Lista de IDs dos frames correspondentes aos color_frames.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (masked_color_frames, frames_with_masks_indices)\n",
        "            - masked_color_frames (list): Lista de frames coloridos com máscaras aplicadas.\n",
        "            - frames_with_masks_indices (list): Lista de números dos frames que possuem máscaras.\n",
        "    \"\"\"\n",
        "    masked_color_frames = []\n",
        "    frames_with_masks_indices = []\n",
        "\n",
        "    for i in tqdm(range(len(color_frames)), desc=\"Aplicando máscaras aos frames coloridos\"):\n",
        "        frame_id = frame_ids[i]\n",
        "        if frame_id in masks_per_frame:\n",
        "            mask = masks_per_frame[frame_id]\n",
        "            frame = color_frames[i]\n",
        "            # Verificar se as dimensões da máscara correspondem às do frame\n",
        "            if mask.shape != frame.shape[:2]:\n",
        "                print(f\"Warning: A máscara para o frame {frame_id} tem dimensões {mask.shape}, mas o frame colorido tem dimensões {frame.shape[:2]}. Ignorando máscara para este frame.\")\n",
        "                continue\n",
        "            # Aplicar máscara ao frame (sobrepor em vermelho)\n",
        "            masked_frame = frame.copy()\n",
        "            masked_frame[mask == 255] = [0, 0, 255]  # Cor vermelha para a máscara\n",
        "            masked_color_frames.append(masked_frame)\n",
        "            frames_with_masks_indices.append(frame_id)\n",
        "        else:\n",
        "            # Nenhuma máscara para este frame\n",
        "            pass\n",
        "\n",
        "    return masked_color_frames, frames_with_masks_indices\n",
        "\n",
        "def save_frames_to_h5(h5f, dataset_name, frames):\n",
        "    \"\"\"\n",
        "    Salva frames em um arquivo .h5 em um dataset específico.\n",
        "\n",
        "    Args:\n",
        "        h5f (h5py.File): Arquivo HDF5 aberto.\n",
        "        dataset_name (str): Nome do dataset dentro do arquivo .h5.\n",
        "        frames (list ou np.ndarray): Lista ou array de frames a serem salvos.\n",
        "    \"\"\"\n",
        "    frames_np = np.array(frames)\n",
        "    if dataset_name in h5f:\n",
        "        print(f\"Atualizando o dataset existente: {dataset_name}\")\n",
        "        del h5f[dataset_name]  # Remove se já existir\n",
        "    h5f.create_dataset(dataset_name, data=frames_np, compression=\"gzip\", compression_opts=4)  # Ajuste o nível de compressão conforme necessário\n",
        "    print(f\"Frames salvos no dataset: {dataset_name}\")\n",
        "\n",
        "def save_frame_names(h5f, dataset_name, frame_names):\n",
        "    \"\"\"\n",
        "    Salva os nomes dos frames em um dataset específico dentro de um arquivo .h5.\n",
        "\n",
        "    Args:\n",
        "        h5f (h5py.File): Arquivo HDF5 aberto.\n",
        "        dataset_name (str): Nome do dataset dentro do arquivo .h5.\n",
        "        frame_names (list): Lista de nomes dos frames.\n",
        "    \"\"\"\n",
        "    # Convertendo para bytes para armazenar strings no HDF5\n",
        "    frame_names_bytes = [name.encode('utf-8') for name in frame_names]\n",
        "    dt = h5py.string_dtype(encoding='utf-8')\n",
        "    if dataset_name in h5f:\n",
        "        print(f\"Atualizando o dataset existente: {dataset_name}\")\n",
        "        del h5f[dataset_name]\n",
        "    h5f.create_dataset(dataset_name, data=frame_names_bytes, dtype=dt)\n",
        "    print(f\"Nomes dos frames salvos no dataset: {dataset_name}\")\n",
        "\n",
        "# ======= 3. Execução Principal =======\n",
        "\n",
        "# 3.1. Abrir os vídeos e obter o número total de frames\n",
        "color_cap = cv2.VideoCapture(color_video_path)\n",
        "thermal_cap = cv2.VideoCapture(thermal_video_path)\n",
        "total_color_frames = int(color_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "total_thermal_frames = int(thermal_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "color_cap.release()\n",
        "thermal_cap.release()\n",
        "\n",
        "# 3.2. Verificar se os vídeos têm o mesmo número de frames\n",
        "if total_color_frames != total_thermal_frames:\n",
        "    print(f\"Atenção: O vídeo colorido tem {total_color_frames} frames e o vídeo térmico tem {total_thermal_frames} frames.\")\n",
        "    total_frames = min(total_color_frames, total_thermal_frames)\n",
        "else:\n",
        "    total_frames = total_color_frames\n",
        "\n",
        "# 3.3. Dividir o vídeo em menos partes para reduzir overhead\n",
        "num_chunks = 3 \n",
        "chunk_size = total_frames // num_chunks\n",
        "\n",
        "# 3.4. Processamento dos Frames Coloridos e Aplicação de Máscaras\n",
        "\n",
        "print(\"\\n=== Processamento dos Frames Coloridos ===\")\n",
        "\n",
        "# Abre o arquivo HDF5 para frames coloridos e mascarados\n",
        "with h5py.File(color_frames_h5_path, 'a') as color_h5, \\\n",
        "     h5py.File(masked_color_frames_h5_path, 'a') as masked_color_h5:\n",
        "    \n",
        "    # Pre-parse todas as anotações relevantes para os frames coloridos\n",
        "    relevant_frames = set(range(total_frames))\n",
        "    masks_per_frame = parse_annotations(annotations_path, relevant_frames, image_shape=(720, 1280, 3))  # Ajuste conforme necessário\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start_frame = i * chunk_size\n",
        "        end_frame = start_frame + chunk_size if i < num_chunks - 1 else total_frames\n",
        "\n",
        "        # Extrair frames coloridos da parte atual\n",
        "        print(f\"\\nProcessando parte {i+1} de {num_chunks}: frames {start_frame} a {end_frame}\")\n",
        "        color_frames_chunk, color_frame_names_chunk = extract_frames(color_video_path, start_frame, end_frame)\n",
        "\n",
        "        # Verificar se frames foram extraídos\n",
        "        if len(color_frames_chunk) == 0:\n",
        "            print(f\"Erro: Nenhum frame colorido extraído da parte {i+1}. Pulando...\")\n",
        "            continue\n",
        "\n",
        "        # Salvar frames coloridos nos arquivos .h5\n",
        "        dataset_color = f\"color_chunk_{i+1}\"\n",
        "        save_frames_to_h5(color_h5, dataset_color, color_frames_chunk)\n",
        "        dataset_color_names = f\"color_chunk_{i+1}_names\"\n",
        "        save_frame_names(color_h5, dataset_color_names, color_frame_names_chunk)\n",
        "\n",
        "        # Aplicar máscaras aos frames coloridos\n",
        "        frame_ids = list(range(start_frame, end_frame))\n",
        "        masked_color_frames_chunk, frames_with_masks_indices_chunk = apply_masks(color_frames_chunk, masks_per_frame, frame_ids)\n",
        "\n",
        "        # Salvar frames com máscaras no arquivo .h5\n",
        "        if masked_color_frames_chunk:\n",
        "            dataset_masked = f\"masked_color_chunk_{i+1}\"\n",
        "            save_frames_to_h5(masked_color_h5, dataset_masked, masked_color_frames_chunk)\n",
        "            dataset_masked_names = f\"masked_color_chunk_{i+1}_names\"\n",
        "            masked_frame_names_chunk = [f\"frame_{idx:06d}\" for idx in frames_with_masks_indices_chunk]\n",
        "            save_frame_names(masked_color_h5, dataset_masked_names, masked_frame_names_chunk)\n",
        "        \n",
        "        # Limpar memória após salvar\n",
        "        del color_frames_chunk\n",
        "        del masked_color_frames_chunk\n",
        "        del frames_with_masks_indices_chunk\n",
        "        del color_frame_names_chunk\n",
        "        print(f\"Memória limpa após salvar a parte {i+1} dos frames coloridos\")\n",
        "\n",
        "# 3.5. Processamento dos Frames Térmicos\n",
        "\n",
        "print(\"\\n=== Processamento dos Frames Térmicos ===\")\n",
        "\n",
        "# Abre o arquivo HDF5 para frames térmicos\n",
        "with h5py.File(thermal_frames_h5_path, 'a') as thermal_h5:\n",
        "    for i in range(num_chunks):\n",
        "        start_frame = i * chunk_size\n",
        "        end_frame = start_frame + chunk_size if i < num_chunks - 1 else total_frames\n",
        "\n",
        "        # Extrair frames térmicos da parte atual\n",
        "        print(f\"\\nProcessando parte {i+1} de {num_chunks}: frames {start_frame} a {end_frame}\")\n",
        "        thermal_frames_chunk, thermal_frame_names_chunk = extract_frames(thermal_video_path, start_frame, end_frame)\n",
        "\n",
        "        # Verificar se frames foram extraídos\n",
        "        if len(thermal_frames_chunk) == 0:\n",
        "            print(f\"Erro: Nenhum frame térmico extraído da parte {i+1}. Pulando...\")\n",
        "            continue\n",
        "\n",
        "        # Salvar frames térmicos nos arquivos .h5\n",
        "        dataset_thermal = f\"thermal_chunk_{i+1}\"\n",
        "        save_frames_to_h5(thermal_h5, dataset_thermal, thermal_frames_chunk)\n",
        "        dataset_thermal_names = f\"thermal_chunk_{i+1}_names\"\n",
        "        save_frame_names(thermal_h5, dataset_thermal_names, thermal_frame_names_chunk)\n",
        "\n",
        "        # Limpar memória após salvar\n",
        "        del thermal_frames_chunk\n",
        "        del thermal_frame_names_chunk\n",
        "        print(f\"Memória limpa após salvar a parte {i+1} dos frames térmicos\")\n",
        "\n",
        "print(\"\\nProcessamento completo.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
