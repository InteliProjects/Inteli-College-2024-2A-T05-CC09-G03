{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNYbH1jSQDkaJuAcULMS06K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_ty7vI6C95j","executionInfo":{"status":"ok","timestamp":1728426395206,"user_tz":180,"elapsed":2513,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}},"outputId":"00b0bfbd-6c04-487d-daf7-3741df1fd89b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["# Instalar as bibliotecas necessárias\n","!pip install torch torchvision\n"]},{"cell_type":"code","source":["# Conexão com o Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvrF78ZlHykW","executionInfo":{"status":"ok","timestamp":1728426396966,"user_tz":180,"elapsed":1764,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}},"outputId":"66625721-afe1-4d87-aa4c-f3cec58223f6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import xml.etree.ElementTree as ET\n","from google.colab.patches import cv2_imshow\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","# Paths to your XML annotations and video file\n","xml_file = '/content/drive/MyDrive/approach_nwot/xml/annotations_new.xml'\n","video_file = '/content/drive/MyDrive/approach_nwot/videos/video_colorido_concatenado_10fps.mp4'\n","\n","# Define crop intervals\n","color_crop_rows = (0, 720)\n","color_crop_cols = (250, 500)\n","\n","def parse_annotations(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","\n","    annotations = {}\n","\n","    for image in root.findall('image'):\n","        image_id = int(image.get('id'))\n","        image_name = image.get('name')\n","\n","        boxes = []\n","        polygons = []\n","        ellipses = []\n","\n","        for box in image.findall('box'):\n","            label = box.get('label')\n","            xtl = float(box.get('xtl'))\n","            ytl = float(box.get('ytl'))\n","            xbr = float(box.get('xbr'))\n","            ybr = float(box.get('ybr'))\n","            boxes.append({'label': label, 'xtl': xtl, 'ytl': ytl, 'xbr': xbr, 'ybr': ybr})\n","\n","        for polygon in image.findall('polygon'):\n","            label = polygon.get('label')\n","            points = polygon.get('points')\n","            point_list = []\n","            for point in points.split(';'):\n","                x_str, y_str = point.split(',')\n","                x = float(x_str)\n","                y = float(y_str)\n","                point_list.append((x, y))\n","            polygons.append({'label': label, 'points': point_list})\n","\n","        for ellipse in image.findall('ellipse'):\n","            label = ellipse.get('label')\n","            cx = float(ellipse.get('cx'))\n","            cy = float(ellipse.get('cy'))\n","            rx = float(ellipse.get('rx'))\n","            ry = float(ellipse.get('ry'))\n","            rotation = float(ellipse.get('rotation', '0.0'))  # Use default value if missing\n","            ellipses.append({'label': label, 'cx': cx, 'cy': cy, 'rx': rx, 'ry': ry, 'rotation': rotation})\n","\n","        annotations[image_id] = {\n","            'name': image_name,\n","            'boxes': boxes,\n","            'polygons': polygons,\n","            'ellipses': ellipses\n","        }\n","    return annotations\n","\n","def adjust_annotations(annotations, crop_rows, crop_cols):\n","    adjusted_annotations = {}\n","    for image_id, data in annotations.items():\n","        adjusted_boxes = []\n","        adjusted_polygons = []\n","        adjusted_ellipses = []\n","\n","        for box in data['boxes']:\n","            xtl = box['xtl'] - crop_cols[0]\n","            ytl = box['ytl'] - crop_rows[0]\n","            xbr = box['xbr'] - crop_cols[0]\n","            ybr = box['ybr'] - crop_rows[0]\n","            # Check if the box is within the crop\n","            if (xtl >= 0 and ytl >= 0 and xbr <= crop_cols[1] - crop_cols[0] and ybr <= crop_rows[1] - crop_rows[0]):\n","                adjusted_boxes.append({\n","                    'label': box['label'],\n","                    'xtl': xtl,\n","                    'ytl': ytl,\n","                    'xbr': xbr,\n","                    'ybr': ybr\n","                })\n","        for polygon in data['polygons']:\n","            adjusted_points = []\n","            for x, y in polygon['points']:\n","                x_adj = x - crop_cols[0]\n","                y_adj = y - crop_rows[0]\n","                # Check if the point is within the crop\n","                if (x_adj >= 0 and x_adj <= crop_cols[1] - crop_cols[0] and y_adj >= 0 and y_adj <= crop_rows[1] - crop_rows[0]):\n","                    adjusted_points.append((x_adj, y_adj))\n","            if adjusted_points:\n","                adjusted_polygons.append({\n","                    'label': polygon['label'],\n","                    'points': adjusted_points\n","                })\n","        for ellipse in data['ellipses']:\n","            cx = ellipse['cx'] - crop_cols[0]\n","            cy = ellipse['cy'] - crop_rows[0]\n","            # Check if the center is within the crop\n","            if (cx >= 0 and cx <= crop_cols[1] - crop_cols[0] and cy >= 0 and cy <= crop_rows[1] - crop_rows[0]):\n","                adjusted_ellipses.append({\n","                    'label': ellipse['label'],\n","                    'cx': cx,\n","                    'cy': cy,\n","                    'rx': ellipse['rx'],\n","                    'ry': ellipse['ry'],\n","                    'rotation': ellipse['rotation']\n","                })\n","\n","        adjusted_annotations[image_id] = {\n","            'name': data['name'],\n","            'boxes': adjusted_boxes,\n","            'polygons': adjusted_polygons,\n","            'ellipses': adjusted_ellipses\n","        }\n","    return adjusted_annotations\n","\n","# Parse and adjust annotations\n","annotations = parse_annotations(xml_file)\n","adjusted_annotations = adjust_annotations(annotations, color_crop_rows, color_crop_cols)\n","\n","# Prepare frames and targets\n","cap = cv2.VideoCapture(video_file)\n","frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(\"Total number of frames:\", frame_count)\n","\n","frames = []\n","targets = []\n","\n","for frame_id in range(frame_count):\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Crop the frame\n","    cropped_frame = frame[color_crop_rows[0]:color_crop_rows[1], color_crop_cols[0]:color_crop_cols[1]]\n","\n","    # Get the adjusted annotations for this frame\n","    if frame_id in adjusted_annotations:\n","        annots = adjusted_annotations[frame_id]\n","\n","        # Collect the annotations\n","        boxes = []\n","        labels = []\n","\n","        for box in annots['boxes']:\n","            xtl = int(box['xtl'])\n","            ytl = int(box['ytl'])\n","            xbr = int(box['xbr'])\n","            ybr = int(box['ybr'])\n","            boxes.append([xtl, ytl, xbr, ybr])\n","            labels.append(box['label'])\n","        # For simplicity, focusing on boxes\n","        if boxes:\n","            frames.append(cropped_frame)\n","            targets.append({'boxes': boxes, 'labels': labels})\n","\n","    else:\n","        # If no annotations, skip\n","        continue\n","\n","cap.release()\n","\n","# Map labels to integers\n","label_set = set()\n","for target in targets:\n","    label_set.update(target['labels'])\n","label_map = {label: idx+1 for idx, label in enumerate(sorted(label_set))}  # +1 because 0 is background\n","\n","# Update targets with integer labels\n","for target in targets:\n","    target['labels'] = [label_map[label] for label in target['labels']]\n","\n","# Define the Dataset class\n","class CowEyeDataset(Dataset):\n","    def __init__(self, frames, targets, transforms=None):\n","        self.frames = frames\n","        self.targets = targets\n","        self.transforms = transforms\n","\n","    def __getitem__(self, idx):\n","        img = self.frames[idx]\n","        target = self.targets[idx]\n","\n","        # Convert image to PIL Image\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = torchvision.transforms.ToPILImage()(img)\n","\n","        # Convert boxes and labels to tensors\n","        boxes = torch.as_tensor(target['boxes'], dtype=torch.float32)\n","        labels = torch.as_tensor(target['labels'], dtype=torch.int64)\n","\n","        # Additional fields required by some models\n","        image_id = torch.tensor([idx])\n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n","\n","        # Create target dictionary\n","        target_dict = {}\n","        target_dict['boxes'] = boxes\n","        target_dict['labels'] = labels\n","        target_dict['image_id'] = image_id\n","        target_dict['area'] = area\n","        target_dict['iscrowd'] = iscrowd\n","\n","        # Apply transforms if any\n","        if self.transforms:\n","            img = self.transforms(img)\n","\n","        return img, target_dict\n","\n","    def __len__(self):\n","        return len(self.frames)\n","\n","# Create the dataset and dataloaders\n","dataset = CowEyeDataset(frames, targets, transforms=torchvision.transforms.ToTensor())\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n","train_dataset = torch.utils.data.Subset(dataset, train_indices)\n","val_dataset = torch.utils.data.Subset(dataset, val_indices)\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","\n","# Define the model\n","num_classes = len(label_map) + 1  # +1 for background\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbNDKnRrLfmF","executionInfo":{"status":"ok","timestamp":1728426530111,"user_tz":180,"elapsed":133148,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}},"outputId":"51861d9c-0af7-4c42-ea56-e746a293fbad"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of frames: 81992\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 165MB/s]\n"]}]},{"cell_type":"code","source":["# Contar o número total de parâmetros\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","# Contar o número de parâmetros treináveis\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total de parâmetros no modelo: {total_params}\")\n","print(f\"Total de parâmetros treináveis: {trainable_params}\")\n"],"metadata":{"id":"a_qOHuR_O5GE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728426530111,"user_tz":180,"elapsed":5,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}},"outputId":"1df026e1-10de-497a-f188-2a379af6a137"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de parâmetros no modelo: 41299161\n","Total de parâmetros treináveis: 41076761\n"]}]},{"cell_type":"code","source":["# Training setup\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","num_epochs = 100\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for images, targets in tqdm(train_loader):\n","        images = list(img.to(device) for img in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","        epoch_loss += losses.item()\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnN1k3RPLouj","executionInfo":{"status":"ok","timestamp":1728427391916,"user_tz":180,"elapsed":238764,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}},"outputId":"967396dd-6abc-4e84-c19c-99fc45fe03b6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.012589297979138792\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Loss: 0.009168655378744006\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Loss: 0.008784425351768732\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Loss: 0.008238861081190407\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Loss: 0.007592676766216755\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6, Loss: 0.006589345599059016\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7, Loss: 0.0069558102870360015\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8, Loss: 0.006400422181468457\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 0.006225594668649137\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10, Loss: 0.0063491288339719175\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11, Loss: 0.00635139555670321\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12, Loss: 0.0062877543736249205\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13, Loss: 0.0061434800270944835\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14, Loss: 0.005730474868323654\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15, Loss: 0.006323444808367639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16, Loss: 0.005347375792916864\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17, Loss: 0.006056372402235865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18, Loss: 0.005496763181872666\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19, Loss: 0.00623655766248703\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20, Loss: 0.007164705381728709\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21, Loss: 0.006627023965120315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22, Loss: 0.006947477138601244\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23, Loss: 0.0064041104167699816\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24, Loss: 0.007286780467256904\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25, Loss: 0.007531064900103956\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26, Loss: 0.0072885866742581126\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27, Loss: 0.007404949294868857\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28, Loss: 0.005517624772619456\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29, Loss: 0.0065369030111469325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30, Loss: 0.005570692475885153\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31, Loss: 0.006154458748642355\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32, Loss: 0.005957001296337694\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33, Loss: 0.0058713629841804504\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34, Loss: 0.005787496885750443\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35, Loss: 0.0064472980098798875\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36, Loss: 0.0058864518185146155\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37, Loss: 0.005832233442924916\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38, Loss: 0.005783454177435488\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39, Loss: 0.006142827461007983\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40, Loss: 0.007001758867409081\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41, Loss: 0.00700876482296735\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42, Loss: 0.008022207021713256\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43, Loss: 0.0064762515132315455\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44, Loss: 0.00609737322665751\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45, Loss: 0.006291490909643471\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46, Loss: 0.0057889682822860776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47, Loss: 0.005143313016742468\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48, Loss: 0.005077120487112552\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49, Loss: 0.006208911864086985\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50, Loss: 0.005460976215545088\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51, Loss: 0.00529369517462328\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52, Loss: 0.0046900614921469245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53, Loss: 0.004120743199018761\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54, Loss: 0.004486953665036708\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55, Loss: 0.004338935331907124\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56, Loss: 0.00520700216293335\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57, Loss: 0.005971789651084691\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58, Loss: 0.0057051477022469045\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59, Loss: 0.006181108776945621\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60, Loss: 0.005383054853882641\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61, Loss: 0.0050921321380883455\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62, Loss: 0.0044662979547865685\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63, Loss: 0.00491188894957304\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64, Loss: 0.0052118061459623275\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65, Loss: 0.004810261027887464\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66, Loss: 0.004495128931012005\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67, Loss: 0.005214054544921964\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68, Loss: 0.005344796704594046\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69, Loss: 0.0049353894544765355\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70, Loss: 0.005174910603091121\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71, Loss: 0.004586280859075487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72, Loss: 0.0042204651865176855\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73, Loss: 0.0045725955627858635\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74, Loss: 0.004372064559720457\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75, Loss: 0.0042394032119773325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76, Loss: 0.004605449223890901\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77, Loss: 0.004795713897328824\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78, Loss: 0.00497496563475579\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79, Loss: 0.004777591733727604\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80, Loss: 0.005831583903636783\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81, Loss: 0.005318398331291973\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82, Loss: 0.004591735580470413\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83, Loss: 0.0048124375403858725\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84, Loss: 0.0054302625940181315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85, Loss: 0.005776310851797461\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86, Loss: 0.0056061763199977575\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87, Loss: 0.005198213830590248\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88, Loss: 0.004991945938672871\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89, Loss: 0.004705138178542257\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90, Loss: 0.0046434313408099115\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91, Loss: 0.003933870827313513\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92, Loss: 0.003952499269507826\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93, Loss: 0.004394660203251988\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94, Loss: 0.0054605759331025185\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95, Loss: 0.0052900991402566435\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96, Loss: 0.004864789382554591\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97, Loss: 0.004979947931133211\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98, Loss: 0.0049946453073062\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99, Loss: 0.00519564087735489\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:02<00:00,  8.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 100, Loss: 0.005751325795426965\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Especifique o intervalo de frames que deseja analisar\n","inicio = 1600  # Frame inicial\n","fim = 2500     # Frame final\n","\n","# Carregar o vídeo\n","cap = cv2.VideoCapture(video_file)\n","\n","# Loop pelos frames especificados\n","for frame_id in range(inicio, fim):\n","    # Posicionar o vídeo no frame desejado\n","    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n","\n","    # Ler o frame\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Crop do frame\n","    cropped_frame = frame[color_crop_rows[0]:color_crop_rows[1], color_crop_cols[0]:color_crop_cols[1]]\n","\n","    # Converter para tensor\n","    img_rgb = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB)\n","    img_tensor = torchvision.transforms.ToTensor()(img_rgb)\n","    img_tensor = img_tensor.to(device)\n","\n","    # Avaliação do modelo sem gradientes\n","    model.eval()\n","    with torch.no_grad():\n","        output = model([img_tensor])\n","\n","    # Visualizar os resultados\n","    img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n","    img = np.ascontiguousarray(img, dtype=np.uint8)\n","\n","    # Extrair boxes, scores e labels\n","    boxes = output[0]['boxes'].cpu().numpy()\n","    scores = output[0]['scores'].cpu().numpy()\n","    labels = output[0]['labels'].cpu().numpy()\n","\n","    # Desenhar as caixas delimitadoras\n","    for box, score, label in zip(boxes, scores, labels):\n","        if score > 0.5:  # Threshold de confiança\n","            xtl, ytl, xbr, ybr = box.astype(int)\n","            cv2.rectangle(img, (xtl, ytl), (xbr, ybr), (0, 255, 0), 2)\n","            label_name = list(label_map.keys())[list(label_map.values()).index(label)]\n","            cv2.putText(img, f\"{label_name}: {score:.2f}\", (xtl, ytl-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 2)\n","\n","    # Converter de volta para RGB para plotagem\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.figure(figsize=(12, 8))\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","\n","# Liberar o vídeo\n","cap.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1NQqvAnMSbzvXw-UxCeE7ariZYOuts7vs"},"id":"f7TGAjiVLq4T","outputId":"32d43fe9-252e-4ce8-dd57-8c639afd2d4d","executionInfo":{"status":"error","timestamp":1728427879326,"user_tz":180,"elapsed":287458,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}}},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Salvar os pesos do modelo\n","torch.save(model.state_dict(), 'modelo_deteccao_olhos.pth')\n","\n","# Salvar o modelo completo (incluindo a arquitetura)\n","torch.save(model, 'modelo_deteccao_olhos_completo.pth')\n"],"metadata":{"id":"ql8tUelYQNzC","executionInfo":{"status":"ok","timestamp":1728427466105,"user_tz":180,"elapsed":1109,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"}}},"execution_count":21,"outputs":[]}]}