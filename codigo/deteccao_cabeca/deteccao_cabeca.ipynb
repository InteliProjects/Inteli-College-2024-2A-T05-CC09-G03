{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Conectando com o Drive"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3242,"status":"ok","timestamp":1728427955957,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"BYK1GkvJvwk8","outputId":"5ea474a1-b80d-4884-e793-5fbde789837e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Conexão com o Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{},"source":["## Instalando as bibliotecas necessárias"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1745,"status":"ok","timestamp":1728427958251,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"I9ZqMZZPCDgt","outputId":"9e9e2c01-5341-4e65-8ca8-875fe6f42565"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["# Instalar as bibliotecas necessárias\n","!pip install torch torchvision"]},{"cell_type":"markdown","metadata":{},"source":["## Importando os dados"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165185,"status":"ok","timestamp":1728428138363,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"BwfNgk9M4XGO","outputId":"b8f6fea2-00ce-4209-8f89-274b729954dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of frames: 81992\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Total parameters in the model: 41299161\n","Total trainable parameters: 41076761\n"]}],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import xml.etree.ElementTree as ET\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","# Paths to your XML annotations and video file\n","xml_file = '/content/drive/MyDrive/approach_nwot/xml/annotations_deteccao.xml'\n","video_file = '/content/drive/MyDrive/approach_nwot/videos/video_colorido_concatenado_10fps.mp4'\n","\n","# Define crop intervals\n","color_crop_rows = (0, 720)\n","color_crop_cols = (250, 500)\n","\n","def parse_annotations(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","\n","    annotations = {}\n","\n","    for track in root.findall('track'):\n","        label = track.get('label')\n","        for box in track.findall('box'):\n","            frame_id = int(box.get('frame'))\n","            outside = int(box.get('outside'))\n","            if outside == 1:\n","                continue  # Skip boxes marked as outside\n","            xtl = float(box.get('xtl'))\n","            ytl = float(box.get('ytl'))\n","            xbr = float(box.get('xbr'))\n","            ybr = float(box.get('ybr'))\n","\n","            # Initialize frame in annotations if not already\n","            if frame_id not in annotations:\n","                annotations[frame_id] = {'boxes': [], 'labels': []}\n","\n","            annotations[frame_id]['boxes'].append([xtl, ytl, xbr, ybr])\n","            annotations[frame_id]['labels'].append(label)\n","\n","    return annotations\n","\n","def adjust_annotations(annotations, crop_rows, crop_cols):\n","    adjusted_annotations = {}\n","    for frame_id, data in annotations.items():\n","        adjusted_boxes = []\n","        adjusted_labels = []\n","\n","        for box, label in zip(data['boxes'], data['labels']):\n","            xtl, ytl, xbr, ybr = box\n","            xtl -= crop_cols[0]\n","            ytl -= crop_rows[0]\n","            xbr -= crop_cols[0]\n","            ybr -= crop_rows[0]\n","            # Check if the box is within the crop\n","            if (xtl >= 0 and ytl >= 0 and xbr <= crop_cols[1] - crop_cols[0] and ybr <= crop_rows[1] - crop_rows[0]):\n","                adjusted_boxes.append([xtl, ytl, xbr, ybr])\n","                adjusted_labels.append(label)\n","\n","        if adjusted_boxes:\n","            adjusted_annotations[frame_id] = {'boxes': adjusted_boxes, 'labels': adjusted_labels}\n","\n","    return adjusted_annotations\n","\n","# Parse and adjust annotations\n","annotations = parse_annotations(xml_file)\n","adjusted_annotations = adjust_annotations(annotations, color_crop_rows, color_crop_cols)\n","\n","# Prepare frames and targets\n","cap = cv2.VideoCapture(video_file)\n","frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(\"Total number of frames:\", frame_count)\n","\n","frames = []\n","targets = []\n","\n","for frame_id in range(frame_count):\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Crop the frame\n","    cropped_frame = frame[color_crop_rows[0]:color_crop_rows[1], color_crop_cols[0]:color_crop_cols[1]]\n","\n","    # Get the adjusted annotations for this frame\n","    if frame_id in adjusted_annotations:\n","        annots = adjusted_annotations[frame_id]\n","\n","        # Collect the annotations\n","        boxes = []\n","        labels = []\n","\n","        for box, label in zip(annots['boxes'], annots['labels']):\n","            xtl, ytl, xbr, ybr = map(int, box)\n","            boxes.append([xtl, ytl, xbr, ybr])\n","            labels.append(label)\n","\n","        frames.append(cropped_frame)\n","        targets.append({'boxes': boxes, 'labels': labels})\n","    else:\n","        # If no annotations, skip\n","        continue\n","\n","cap.release()\n","\n","# Map labels to integers\n","label_set = set()\n","for target in targets:\n","    label_set.update(target['labels'])\n","label_map = {label: idx+1 for idx, label in enumerate(sorted(label_set))}  # +1 because 0 is background\n","\n","# Update targets with integer labels\n","for target in targets:\n","    target['labels'] = [label_map[label] for label in target['labels']]\n","\n","# Define the Dataset class\n","class CowHeadDataset(Dataset):\n","    def __init__(self, frames, targets, transforms=None):\n","        self.frames = frames\n","        self.targets = targets\n","        self.transforms = transforms\n","\n","    def __getitem__(self, idx):\n","        img = self.frames[idx]\n","        target = self.targets[idx]\n","\n","        # Convert image to PIL Image\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = torchvision.transforms.ToPILImage()(img)\n","\n","        # Convert boxes and labels to tensors\n","        boxes = torch.as_tensor(target['boxes'], dtype=torch.float32)\n","        labels = torch.as_tensor(target['labels'], dtype=torch.int64)\n","\n","        # Additional fields required by some models\n","        image_id = torch.tensor([idx])\n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n","\n","        # Create target dictionary\n","        target_dict = {}\n","        target_dict['boxes'] = boxes\n","        target_dict['labels'] = labels\n","        target_dict['image_id'] = image_id\n","        target_dict['area'] = area\n","        target_dict['iscrowd'] = iscrowd\n","\n","        # Apply transforms if any\n","        if self.transforms:\n","            img = self.transforms(img)\n","\n","        return img, target_dict\n","\n","    def __len__(self):\n","        return len(self.frames)"]},{"cell_type":"markdown","metadata":{},"source":["## Criando dataset e definindo o modelo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the dataset and dataloaders\n","dataset = CowHeadDataset(frames, targets, transforms=torchvision.transforms.ToTensor())\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n","train_dataset = torch.utils.data.Subset(dataset, train_indices)\n","val_dataset = torch.utils.data.Subset(dataset, val_indices)\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","\n","# Define the model\n","num_classes = len(label_map) + 1  # +1 for background\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Count the number of parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total parameters in the model: {total_params}\")\n","print(f\"Total trainable parameters: {trainable_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Treinando o modelo"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1063788,"status":"ok","timestamp":1728429355008,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"gtRNlxz8VWQc","outputId":"0df85763-fd38-431c-8348-ce8646da65d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.0500256617863973\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 0.04520623510082563\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 0.042717597509423895\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 0.038692340006430945\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 0.031075355658928553\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 0.02854727494219939\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 0.028588796158631642\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 0.022421305254101753\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 0.021941665187478067\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.021859027072787286\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Loss: 0.022481579209367435\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12, Loss: 0.022465495206415654\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13, Loss: 0.019998469079534214\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14, Loss: 0.01846988368779421\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15, Loss: 0.016955371821920077\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16, Loss: 0.015105853974819183\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17, Loss: 0.013982832493881384\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18, Loss: 0.013478715904057026\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19, Loss: 0.013251792391141255\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.012800544251998265\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21, Loss: 0.014947186720867952\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22, Loss: 0.014842576595644157\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23, Loss: 0.01767330088963111\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24, Loss: 0.015461222268640995\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25, Loss: 0.013507809241612751\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26, Loss: 0.012171666386226814\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27, Loss: 0.012531565502285957\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28, Loss: 0.01168876929829518\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29, Loss: 0.01177396128575007\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.010804286474982898\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31, Loss: 0.011885684759666523\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32, Loss: 0.014253593360384306\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33, Loss: 0.013040630860875051\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34, Loss: 0.013132496550679208\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35, Loss: 0.011943343126525481\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36, Loss: 0.010679795903464158\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37, Loss: 0.009280300854394833\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38, Loss: 0.009432066914935906\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39, Loss: 0.01061465973034501\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.009610622593512138\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41, Loss: 0.010710430517792701\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42, Loss: 0.011103912846495707\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43, Loss: 0.011249647134294112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44, Loss: 0.010879618519296249\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45, Loss: 0.010541179000089567\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46, Loss: 0.008668610608826082\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 47, Loss: 0.008191309062143166\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 48, Loss: 0.007548483290399114\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49, Loss: 0.007964725140482187\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.007903222957005103\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 51, Loss: 0.008357648675640424\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 52, Loss: 0.008117486909031867\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 53, Loss: 0.008514078675458829\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 54, Loss: 0.008121336965511242\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 55, Loss: 0.011088095139712095\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 56, Loss: 0.010756445396691561\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 57, Loss: 0.00960309775546193\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 58, Loss: 0.00836073827619354\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 59, Loss: 0.00894675636664033\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.007853489896903435\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 61, Loss: 0.0072843298626442754\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 62, Loss: 0.006918978784233332\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 63, Loss: 0.007270065974444151\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64, Loss: 0.00667716107952098\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 65, Loss: 0.0067976101612051325\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 66, Loss: 0.007552044248829285\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 67, Loss: 0.006534537393599748\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 68, Loss: 0.006570879897723595\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 69, Loss: 0.006268517641971508\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.007803242063770691\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 71, Loss: 0.006541486922651529\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72, Loss: 0.0068905923515558245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 73, Loss: 0.006597171071916819\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 74, Loss: 0.007120538658152024\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 75, Loss: 0.006498626464356979\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 76, Loss: 0.007892819090435902\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 77, Loss: 0.006277887662872672\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 78, Loss: 0.006227579743911822\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 79, Loss: 0.0058018673832217855\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.006946148723363877\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 81, Loss: 0.011352210802336534\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 82, Loss: 0.012297073379158974\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 83, Loss: 0.011249029201765855\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 84, Loss: 0.008996288136889538\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85, Loss: 0.010124681983143091\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 86, Loss: 0.008026736478010813\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 87, Loss: 0.0068102001833419004\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 88, Loss: 0.007953545513252417\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 89, Loss: 0.006073700698713462\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.007386318780481816\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 91, Loss: 0.005857235348472992\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:11<00:00,  1.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 92, Loss: 0.006863554411878189\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 93, Loss: 0.0062397093201677\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 94, Loss: 0.007042252365499735\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 95, Loss: 0.006845310050994158\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 96, Loss: 0.007892053915808599\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 97, Loss: 0.007802837993949652\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 98, Loss: 0.007488517463207245\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 99, Loss: 0.007535279635339976\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.009284294582903386\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Training setup\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","num_epochs = 100  # Adjust the number of epochs as needed\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for images, targets in tqdm(train_loader):\n","        images = list(img.to(device) for img in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","        epoch_loss += losses.item()\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Analisando o resultado do modelo fazendo inferência em um vídeo importado"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AF1QkHNqQrMeAileOE6DZM3DEKUJPCnJ"},"executionInfo":{"elapsed":96537,"status":"ok","timestamp":1728429452040,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"r9SfixNrBF-q","outputId":"0aed5d02-7a2f-44da-8067-fd45ed5b0634"},"outputs":[],"source":["# Specify the range of frames you want to analyze\n","start_frame = 1500  # Start frame\n","end_frame = 1600    # End frame\n","\n","# Load the video\n","cap = cv2.VideoCapture(video_file)\n","\n","# Loop through the specified frames\n","for frame_id in range(start_frame, end_frame):\n","    # Position the video at the desired frame\n","    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n","\n","    # Read the frame\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Crop the frame\n","    cropped_frame = frame[color_crop_rows[0]:color_crop_rows[1], color_crop_cols[0]:color_crop_cols[1]]\n","\n","    # Convert to tensor\n","    img_rgb = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB)\n","    img_tensor = torchvision.transforms.ToTensor()(img_rgb)\n","    img_tensor = img_tensor.to(device)\n","\n","    # Model evaluation without gradients\n","    model.eval()\n","    with torch.no_grad():\n","        output = model([img_tensor])\n","\n","    # Visualize the results\n","    img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n","    img = np.ascontiguousarray(img, dtype=np.uint8)\n","\n","    # Extract boxes, scores, and labels\n","    boxes = output[0]['boxes'].cpu().numpy()\n","    scores = output[0]['scores'].cpu().numpy()\n","    labels = output[0]['labels'].cpu().numpy()\n","\n","    # Draw bounding boxes\n","    for box, score, label in zip(boxes, scores, labels):\n","        if score > 0.5:  # Confidence threshold\n","            xtl, ytl, xbr, ybr = box.astype(int)\n","            cv2.rectangle(img, (xtl, ytl), (xbr, ybr), (0, 255, 0), 2)\n","            label_name = list(label_map.keys())[list(label_map.values()).index(label)]\n","            cv2.putText(img, f\"{label_name}: {score:.2f}\", (xtl, ytl-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 2)\n","\n","    # Convert back to RGB for plotting\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.figure(figsize=(12, 8))\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","\n","# Release the video\n","cap.release()\n"]},{"cell_type":"markdown","metadata":{},"source":["A seguir, salvamos tanto os pesos do modelo, quanto o modelo completo"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":502,"status":"ok","timestamp":1728429355505,"user":{"displayName":"Turma 5 - Grupo 3","userId":"02572953562150552524"},"user_tz":180},"id":"7bN8c6twXIu_"},"outputs":[],"source":["# Salvar os pesos do modelo\n","torch.save(model.state_dict(), 'modelo_deteccao_cabeca.pth')\n","\n","# Salvar o modelo completo (incluindo a arquitetura)\n","torch.save(model, 'modelo_deteccao_cabeca_completo.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Visualizando os resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SNdL_B10I45JWQh2lpLfOA9JPlR3cCFT"},"id":"laypTS6_V8Tf","outputId":"da2729b8-71c0-47a3-9687-2b410bdfc994"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Visualization of results\n","model.eval()\n","import random\n","\n","num_images_to_show = 40\n","for idx in random.sample(range(len(val_dataset)), num_images_to_show):\n","    img, target = val_dataset[idx]\n","    # img is a tensor, move to device\n","    img = img.to(device).float() / 255.0  # Converte para float32 e normaliza\n","    # Run the model\n","    with torch.no_grad():\n","        prediction = model([img])\n","    # Convert image to CPU and numpy\n","    img_np = img.cpu().numpy()\n","    img_np = np.transpose(img_np, (1, 2, 0))\n","    img_np = (img_np * 255).astype(np.uint8)\n","    # Plot the image\n","    fig, ax = plt.subplots(1, figsize=(12, 9))\n","    ax.imshow(img_np)\n","    # Plot ground truth boxes in green\n","    boxes = target['boxes'].cpu().numpy()\n","    for box in boxes:\n","        rect = plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n","                             linewidth=2, edgecolor='g', facecolor='none')\n","        ax.add_patch(rect)\n","    # Plot predicted boxes in red\n","    pred_boxes = prediction[0]['boxes'].cpu().numpy()\n","    pred_scores = prediction[0]['scores'].cpu().numpy()\n","    # Only plot boxes with score above a threshold\n","    threshold = 0.5\n","    for box, score in zip(pred_boxes, pred_scores):\n","        if score > threshold:\n","            rect = plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n","                                 linewidth=2, edgecolor='r', facecolor='none')\n","            ax.add_patch(rect)\n","    plt.axis('off')\n","    plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNDRVrc3o8rv4iq7XhpS906","gpuType":"T4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
